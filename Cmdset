bai
path:
/home/tbai/mmdetection/mmdetection/rtmdet_pose_ext
/home/tbai/baimmdet

训练cmd




claude --resume c8b1e93e-f88e-4ec9-8581-858fa3521bdf


tensorboard --logdir work_dirs/rtmdet_pose_0212_v2/ --port 6006
ssh -L 6006:localhost:6006 tbai@dst-mikrowelle.etit.tu-chemnitz.de
http://localhost:6006
tensorboard --logdir work_dirs/rtmdet_pose_regression/ --port 6008

cd ~/mmdetection/mmdetection
tensorboard --logdir work_dirs/rtmdet_pose_0212 --port 6006 --bind_all


export CUDA_VISIBLE_DEVICES=1 
python tools/train.py rtmdet_pose_v4.py --work-dir work_dirs/rtmdet_pose_v4/

export CUDA_VISIBLE_DEVICES=1 
python tools/train.py rtmdet_pose_clean.py --work-dir work_dirs/rtmdet_pose_0212_v2/

export CUDA_VISIBLE_DEVICES=0 
python tools/train.py rtmdet_pose_regression.py --work-dir work_dirs/rtmdet_pose_regression/

如果遇到gpu崩溃，mikro这个电脑老崩
使用：
python tools/train.py rtmdet_pose_clean.py \
  --work-dir work_dirs/rtmdet_pose_0206/ \
  --resume

微调
python tools/train.py rtmdet_pose_finetune.py --work-dir work_dirs/rtmdet_pose_finetune/

qQ947425517.

python tools/test.py rtmdet_pose_clean.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_0211/best_coco_bbox_mAP_epoch_48.pth

python tools/test.py rtmdet_pose_finetune.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_finetune/best_coco_bbox_mAP_epoch_*.pth   


python pose_infer/inference.py \
    --config /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_clean/rtmdet_pose_clean.py \
    --checkpoint /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_0211/best_coco_bbox_mAP_epoch_48.pth \
    --input /home/tbai/Desktop/SenIRDatasetProcessed/1A-2\ Walking/AAG/stitched_png \
    --output /home/tbai/Desktop/results0211/ \
    --det-thr 0.1 \
    --kpt-thr 0.1 \
    --radius 1 
    
pipeline :
The image is processed through a Backbone and Neck to obtain FPN features [P3, P4, P5]. Then, RTMDetHead is used to predict the bounding box (x1, y1, x2, y2). In RoIAlign, the features are clipped from the FPN using the four corners of the bounding box, resulting in a 48×48 feature map. Next, HeatmapHead is used to predict heatmaps, obtaining 7 keypoints, resulting in 96×96 heat maps. Finally, these are decoded and mapped back to the image's coordinate system.

  训练流程对应代码：
   rtmdet_with_pose.py:71   loss()  
   检测loss    rtmdet_with_pose.py:91  bbox_head.loss(x, ...)
   构建GT RoIs  rtmdet_with_pose.py:262  _build_gt_rois()
    RoI特征裁剪  rtmdet_with_pose.py:116  pose_roi_extractor(x, rois)  
    生成热图GT   heatmap_head.py:319      _build_targets_from_rois() 
    关键点映射   heatmap_head.py:425      _map_keypoints_to_img() + 左右交换 
    Pose loss    heatmap_head.py:184      MSE(pred_heatmap, gt_heatmap)  


Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.553
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  0.819
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] =  0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.573
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  0.831
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] =  0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = -1.000
02/11 13:20:25 - mmengine - INFO - Epoch(test) [1194/1194]    coco/bbox_mAP: 0.8870  coco/bbox_mAP_50: 0.9810  coco/bbox_mAP_75: 0.9480  coco/bbox_mAP_s: 0.8870  coco/bbox_mAP_m: 0.8220  coco/bbox_mAP_l: -1.0000  coco/AP: 0.5525  coco/AP .5: 0.8187  coco/AP .75: 0.4585  coco/AP (M): 0.0000  coco/AP (L): -1.0000  coco/AR: 0.5735  coco/AR .5: 0.8311  coco/AR .75: 0.4943  coco/AR (M): 0.0000  coco/AR (L): -1.0000  data_time: 0.0020  time: 0.1327


















