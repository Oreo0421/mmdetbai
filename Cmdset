bai
path:
/home/tbai/mmdetection/mmdetection/rtmdet_pose_ext
/home/tbai/baimmdet

训练cmd

export CUDA_VISIBLE_DEVICES=0
python tools/train.py rtmdet_pose_v4.py --work-dir work_dirs/rtmdet_pose_v4_3  



tensorboard --logdir work_dirs/rtmdet_pose_v6/ --port 6006
ssh -L 6006:localhost:6006 tbai@dst-mikrowelle.etit.tu-chemnitz.de

http://localhost:6006

tensorboard --logdir work_dirs/rtmdet_pose_regression/ --port 6008

cd ~/mmdetection/mmdetection
tensorboard --logdir work_dirs/rtmdet_pose_0212 --port 6006 --bind_all


export CUDA_VISIBLE_DEVICES=1 
python tools/train.py rtmdet_pose_v4.py --work-dir work_dirs/rtmdet_pose_v4/

export CUDA_VISIBLE_DEVICES=1 
python tools/train.py rtmdet_pose_clean.py --work-dir work_dirs/rtmdet_pose_0212_v2/

export CUDA_VISIBLE_DEVICES=0 
python tools/train.py rtmdet_pose_regression.py --work-dir work_dirs/rtmdet_pose_regression/

python tools/train.py rtmdet_pose_v5.py --work-dir work_dirs/rtmdet_pose_v5/

 python tools/train.py rtmdet_pose_v6.py --work-dir work_dirs/rtmdet_pose_v6



 python tools/train.py rtmdet_pose_v7_withclass_track.py --work-dir work_dirs/rtmdet_pose_v7_withclass_track

如果遇到gpu崩溃，mikro这个电脑老崩
使用：
python tools/train.py rtmdet_pose_clean.py \
  --work-dir work_dirs/rtmdet_pose_0206/ \
  --resume




微调
python tools/train.py rtmdet_pose_finetune.py --work-dir work_dirs/rtmdet_pose_finetune/

qQ947425517.

python tools/test.py rtmdet_pose_clean.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_0211/best_coco_bbox_mAP_epoch_48.pth

python tools/test.py rtmdet_pose_finetune.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_finetune/best_coco_bbox_mAP_epoch_*.pth   

python tools/test.py rtmdet_pose_v4.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_v4_3/best_coco_bbox_mAP_epoch_77.pth   

python tools/test.py rtmdet_pose_v6.py /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_v6/best_coco_bbox_mAP_epoch_75.pth   

python pose_infer/inference.py \
    --config /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_clean/rtmdet_pose_clean.py \
    --checkpoint /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_0211/best_coco_bbox_mAP_epoch_48.pth \
    --input /home/tbai/Desktop/SenIRDatasetProcessed/1A-2\ Walking/AAG/stitched_png \
    --output /home/tbai/Desktop/results0211/ \
    --det-thr 0.1 \
    --kpt-thr 0.1 \
    --radius 1 
    

  python pose_infer/infer_simdr.py \
    --radius 1 \
    --config /home/tbai/mmdetection/mmdetection/rtmdet_pose_v6.py \
    --checkpoint /home/tbai/mmdetection/mmdetection/work_dirs/rtmdet_pose_v6/best_coco_bbox_mAP_epoch_75.pth \
    --input /home/tbai/Desktop/SenIRDatasetProcessed/1A-2\ Walking/AAG/stitched_png \
    --output /home/tbai/Desktop/results0213_v6/

pipeline :
The image is processed through a Backbone and Neck to obtain FPN features [P3, P4, P5]. Then, RTMDetHead is used to predict the bounding box (x1, y1, x2, y2). In RoIAlign, the features are clipped from the FPN using the four corners of the bounding box, resulting in a 48×48 feature map. Next, HeatmapHead is used to predict heatmaps, obtaining 7 keypoints, resulting in 96×96 heat maps. Finally, these are decoded and mapped back to the image's coordinate system.

  训练流程对应代码：
   rtmdet_with_pose.py:71   loss()  
   检测loss    rtmdet_with_pose.py:91  bbox_head.loss(x, ...)
   构建GT RoIs  rtmdet_with_pose.py:262  _build_gt_rois()
    RoI特征裁剪  rtmdet_with_pose.py:116  pose_roi_extractor(x, rois)  
    生成热图GT   heatmap_head.py:319      _build_targets_from_rois() 
    关键点映射   heatmap_head.py:425      _map_keypoints_to_img() + 左右交换 
    Pose loss    heatmap_head.py:184      MSE(pred_heatmap, gt_heatmap)  


Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.553
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  0.819
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] =  0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.573
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  0.831
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] =  0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = -1.000
02/11 13:20:25 - mmengine - INFO - Epoch(test) [1194/1194]    coco/bbox_mAP: 0.8870  coco/bbox_mAP_50: 0.9810  coco/bbox_mAP_75: 0.9480  coco/bbox_mAP_s: 0.8870  coco/bbox_mAP_m: 0.8220  coco/bbox_mAP_l: -1.0000  coco/AP: 0.5525  coco/AP .5: 0.8187  coco/AP .75: 0.4585  coco/AP (M): 0.0000  coco/AP (L): -1.0000  coco/AR: 0.5735  coco/AR .5: 0.8311  coco/AR .75: 0.4943  coco/AR (M): 0.0000  coco/AR (L): -1.0000  data_time: 0.0020  time: 0.1327



============================================
v4_2

 (HeatmapHeadV4 + rtmdet_pose_v4.py)                                                                                                                                                                           
 重新设计 loss：                                                                                                                                                                                                                                                                                      
   前景加权 MSE       peak 像素 ×10，背景 ×1，解决 91% 背景稀释问题                           

  可见性分支        GAP→FC→sigmoid，预测每个点是否可见（BCE loss）                          

  三级权重           v=0 图外: loc=0,vis=0；v=1 遮挡: loc=0.3,vis=0；v=2 可见: loc=1.0,vis=1 

  per-keypoint 平均  固定除以 K=7，不随可见点数波动                                          
 
  upsample_factor=2 │ 48→96×96 heatmap，减少量化误差                                    

  sigma=3.0         配合 96×96，更宽容的高斯目标                                          

  sigmas=[0.2]       OKS 评估容差放宽                                                


  Loss 公式： loss = 5.0 × fg_weighted_MSE + 1.0 × BCE_vis

  mAp 提升到58%

  V5 HeatmapHeadV4 

  V4。2 的 config 基础上加数据增强：
       改动                               内容                         
  
   旋转增强       RandomRotateWithPose(±20°, prob=0.5)，画布扩展不裁切 
  
 sigmas=[0.25] 评估容差从 0.2 → 0.25                                
 
  Head/Loss 不变，和 V4 完全一样。

  结果： kpt AP = 0.570（和 V4 几乎相同，旋转增强对此数据集无明显帮助、

  对比V4，2无改变

v5

  V5.2 (HeatmapHeadV5 + rtmdet_pose_v5.py)

  在 V4 loss j加上 soft-argmax 坐标回归：

  soft-argmax      heatmap × temperature(β=10)  softmax  期望坐标，可导
 
  SmoothL1 坐标 loss 直接优化预测坐标与 GT 坐标的距离                      

   精确 GT 坐标      浮点坐标（无量化），比 heatmap 的整数 argmax 更精确    
 
  Loss 公式： loss = 5.0 × fg_weighted_MSE + 1.0 × BCE_vis + 0.5 × SmoothL1_coord


v6:
  
            V4 (2D Heatmap)        V6 (SimDR 1D)      
  
  预测   96×96 2D 热图         两条 96-bin 1D 向量    
  
  Loss    MSE(前景加权)          KL 散度(1D 高斯)   
  
  上采样 deconv 48→96          1D ConvTranspose      
  
   解码    2D argmax + sub-pixel 1D argmax / scale      
 
 量化   1/96 像素              1/96 像素(但 x,y 独立) 






=================================================================================
  # 图片文件夹 (单帧, 无跟踪)                                                                                                                                                                                      
  python pose_infer/infer_classifyandpred.py \                
      --config rtmdet_pose_v7_withclass_track.py \                                                                                                                                                                 
      --checkpoint work_dirs/xxx/best.pth \                                                                                                                                                                        
      --input /path/to/images \
      --output /path/to/results

  # 图片文件夹 + ByteTrack 时序 GRU
  python pose_infer/infer_classifyandpred.py \
      --config rtmdet_pose_v7_withclass_track.py \
      --checkpoint work_dirs/xxx/best.pth \
      --input /path/to/images \
      --output /path/to/results \
      --use-tracker

  # 视频文件 (自动启用 tracker + 保存视频)
  python pose_infer/infer_classifyandpred.py \
      --input /path/to/video.mp4 \
      --save-video

  可视化效果：
  - 正常 → 绿框 + normal(0.12)
  - 跌倒 → 红框 + FALLING(0.87) + FALL DETECTED 警告

  - tracker 模式额外显示 ID:3 跟踪编号

❯ 多个图片帧                                                                                                                                                                                                 
                                                                                                                                                                                         
                                                              
  python pose_infer/infer_classifyandpred.py --config rtmdet_pose_v7_withclass_track.py                                                                                --input /path/to/sequential_frames/ \                                      
      --checkpoint work_dirs/xxx/best.pth \                                                                                                                                                                        
      --use-tracker  







